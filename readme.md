#  Curso Apache Airflow - Entorno en GitHub Codespaces

Este repositorio contiene el entorno listo para ejecutar **Apache Airflow** en la nube usando **GitHub Codespaces**. No necesitas instalar nada en tu computadora.

> Ideal para estudiantes del curso de Airflow que quieren desarrollar, probar y visualizar DAGs desde el navegador.

---

##  Â¿QuÃ© es GitHub Codespaces?

GitHub Codespaces es un entorno de desarrollo en la nube. Este repositorio incluye una configuraciÃ³n que levanta Apache Airflow con Docker y te permite acceder a su interfaz web directamente desde el navegador.

---

##  Requisitos

- Una cuenta de GitHub.
- Acceso a [GitHub Codespaces](https://github.com/features/codespaces) (gratis hasta 60 horas por mes).
- Navegador web moderno.

---

##  CÃ³mo usar este entorno (paso a paso)

### 1. AbrÃ­ un Codespace

1. EntrÃ¡ a este repositorio (o tu fork si preferÃ­s).
2. HacÃ© clic en el botÃ³n verde `<> Code`.
3. SeleccionÃ¡ la pestaÃ±a **"Codespaces"**.
4. HacÃ© clic en **â€œCreate codespace on mainâ€**.

>  EsperÃ¡ unos minutos mientras se configura el entorno.

---

### 2. Inicializar Airflow

Cuando se abra Codespaces, hacÃ© lo siguiente:

1. AbrÃ­ la terminal integrada (`Ctrl+Shift+Ã±` o "Terminal > New Terminal").
2. EjecutÃ¡ estos comandos:

```bash
# Inicializar la base de datos de Airflow (solo la primera vez)
docker compose up airflow-init

# Iniciar los servicios
docker compose up
```

---

### 3. AccedÃ© a la interfaz web de Airflow

1. HacÃ© clic en el Ã­cono `Ports` en el panel izquierdo de GitHub Codespaces (ðŸ”Œ).
2. BuscÃ¡ el puerto `8080`, y hacÃ© clic en **"Open in Browser"**.
3. IngresÃ¡ con estas credenciales:

```
Usuario: airflow
ContraseÃ±a: airflow
```

---

### 4. AgregÃ¡ tus propios DAGs

- Los DAGs estÃ¡n en la carpeta `/dags`.
- PodÃ©s crear archivos nuevos `.py` o editar los existentes.
- Airflow detectarÃ¡ automÃ¡ticamente los cambios.

Ejemplo rÃ¡pido (ya incluido en este repo):

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG('hola_mundo', start_date=datetime(2023, 1, 1), schedule_interval='@daily', catchup=False) as dag:
    tarea = BashOperator(
        task_id='imprimir_mensaje',
        bash_command='echo "Hola mundo desde Airflow!"'
    )
```

---

### 5. Detener y reiniciar Airflow

Para detener:

```bash
docker compose down
```

Para reiniciar:

```bash
docker compose up
```

---

###  Â¿QuerÃ©s reiniciar todo desde cero?

Si querÃ©s eliminar todos los datos y reiniciar desde cero:

```bash
docker compose down --volumes --remove-orphans
```

---

##  Estructura del Proyecto

```
.
â”œâ”€â”€ dags/               # DAGs del curso
â”œâ”€â”€ docker-compose.yaml # ConfiguraciÃ³n de servicios
â”œâ”€â”€ .env                # UID para evitar errores de permisos
â”œâ”€â”€ .devcontainer/      # ConfiguraciÃ³n para Codespaces
â”‚   â””â”€â”€ Dockerfile
â””â”€â”€ devcontainer.json   # Entradas necesarias para el entorno remoto
```

---

##  Â¿Dudas o errores?

1. VerificÃ¡ que los contenedores estÃ©n corriendo:

```bash
docker compose ps
```

2. RevisÃ¡ los logs:

```bash
docker compose logs
```

3. PreguntÃ¡ a tu profesor o en el foro del curso.

---

Â¡Listo! Ya estÃ¡s trabajando con Airflow desde la nube 

# Nota:
```bash
# Comandos utiles
docker-compose restart airflow-scheduler
docker-compose logs airflow-worker
docker-compose exec airflow-webserver airflow dags list
docker-compose logs airflow-scheduler
docker-compose exec airflow-webserver airflow dags list-import-errors


```
